{
	"name": "Parametros",
	"properties": {
		"folder": {
			"name": "Data Flow"
		},
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"linkedService": {
						"referenceName": "AzureSqlDatabaseRepasoADF",
						"type": "LinkedServiceReference"
					},
					"name": "sourceEmpleado"
				}
			],
			"sinks": [
				{
					"linkedService": {
						"referenceName": "LinkedService_BlobStorage",
						"type": "LinkedServiceReference"
					},
					"name": "sinkReporteEmpleado"
				}
			],
			"transformations": [
				{
					"name": "filter"
				}
			],
			"scriptLines": [
				"parameters{",
				"     cargo as string",
				"}",
				"source(output(",
				"          Nombre as string,",
				"          Cargo as string,",
				"          FechaContratacion as date,",
				"          Telefono as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     format: 'procedure',",
				"     store: 'sqlserver',",
				"     procedureName: 'SP_REP_EMP_CARGO',",
				"     schemaName: 'dbo',",
				"     resultSet: true,",
				"     isolationLevel: 'READ_UNCOMMITTED') ~> sourceEmpleado",
				"sourceEmpleado filter(Cargo==$cargo) ~> filter",
				"filter sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     format: 'delimited',",
				"     container: 'dataflowdataset',",
				"     folderPath: 'Parametros',",
				"     columnDelimiter: ',',",
				"     escapeChar: '\\\\',",
				"     quoteChar: '\\\"',",
				"     columnNamesAsHeader: true,",
				"     partitionFileNames:['ReporteEmpleado.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sinkReporteEmpleado"
			]
		}
	}
}